{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: True\n",
      "GPU 이름: NVIDIA GeForce RTX 4070 SUPER\n",
      "CUDA 버전: 11.8\n",
      "PyTorch 버전: 2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA 버전:\", torch.version.cuda)\n",
    "    print(\"PyTorch 버전:\", torch.__version__)\n",
    "else:\n",
    "    print(\"GPU가 인식되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb929780ece4a3485365eb021a02447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 로그인\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 줄씩 실행\n",
    "# pip uninstall tensorflow -y\n",
    "# pip install --upgrade --force-reinstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad037ff3273444d9d4ba68fe33e9c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# # 9/5B\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# # model_name = \"beomi/KoAlpaca-Polyglot-5.8B\"\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",  # GPU 자동 배분\n",
    "#     torch_dtype=\"auto\"\n",
    "# )\n",
    "\n",
    "# llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# CPU로 모델 로드 (device_map 제거)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\"  # 또는 명시적으로 torch.float16 등\n",
    ")\n",
    "\n",
    "# PAD 토큰 추가 및 토큰 임베딩 사이즈 조정\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 모델을 GPU로 이동 (예: cuda 사용)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "다음은 연예인 스캔들과 관련된 기사입니다:\n",
      "\n",
      "\"2020년 5월 17일 발매된 슈가의 믹스테잎 수록곡이 특정 단체와 관련된 인물의 연설을 사용하여 논란이 되었습니다.\"\n",
      "\n",
      "이 사건의 주요 키워드는 무엇인가요? 핵심 단어 3~5개 정도를 중심 문장으로 설명해주세요.\n",
      "\n",
      "\n",
      "\"2020년 5월 17일 발매된 슈가의 믹스테잎 수록곡이 특정 단체와 관련된 인물의 연설을 사용하여 논란이 되었습니다.\"\n",
      "\n",
      "중요 키워드: wumixsteper, 2020년 5월 17일, 슈가, 믹스테잎 수록곡, 특정 단체와 관련된 인물의 연설,\n"
     ]
    }
   ],
   "source": [
    "### prac\n",
    "prompt = \"\"\"\n",
    "다음은 연예인 스캔들과 관련된 기사입니다:\n",
    "\n",
    "\"2020년 5월 17일 발매된 슈가의 믹스테잎 수록곡이 특정 단체와 관련된 인물의 연설을 사용하여 논란이 되었습니다.\"\n",
    "\n",
    "이 사건의 주요 키워드는 무엇인가요? 핵심 단어 3~5개 정도를 중심 문장으로 설명해주세요.\n",
    "\"\"\"\n",
    "\n",
    "output = llm(prompt, max_new_tokens=150, temperature=0.7, \n",
    "             do_sample=True  # 샘플링 활성화\n",
    "             )[0]['generated_text']\n",
    "print(output)\n",
    "\n",
    "\n",
    "\n",
    "# response = llm(prompt, max_new_tokens=150, temperature=0.7, do_sample=True)[0]['generated_text']\n",
    "# print(response)\n",
    "\n",
    "# from keybert import KeyBERT\n",
    "\n",
    "# kw_model = KeyBERT()\n",
    "\n",
    "# keywords = kw_model.extract_keywords(response, top_n=5, stop_words='korean')\n",
    "\n",
    "# print(\"▶ 추출된 키워드:\")\n",
    "# for kw in keywords:\n",
    "#     print(\"-\", kw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "다음 기사 내용을 분석하여, \n",
      "1. 기사에서 다루는 스캔들의 핵심 키워드를 중복 없이 3~5개 추출해 주세요. 스캔들에 포함된 사건과 관련된 요소가 있다면 반드시 포함해 주세요.\n",
      "2. 해당 스캔들의 유형을 분류할 때, 스캔들이 어떤 사건이나 논란(예: 음원 샘플링 논란, 가사/표현 논란, 사회적/정치적 이슈 등)에 근거하여 발생했는지를 명확하게 설명해 주세요. 특히, 인민사원 집단 자살 사건과 연결된 부분은 반드시 언급하여 분류에 반영해 주세요.\n",
      "\n",
      "출력 형식은 반드시 아래의 두 부분만 작성해 주세요:\n",
      "- 핵심 키워드: [키워드1, 키워드2, ...]\n",
      "- 스캔들 유형: [분류 결과]\n",
      "\n",
      "\n",
      "아래 기사를 참고하여 작업해 주세요.\n",
      "--------------------------------------------------\n",
      "2020년 5월 17일 발매된 슈가의 믹스테잎\n",
      "D-2\n",
      "의 수록곡 <어떻게 생각해?>의 도입부에\n",
      "인민사원 집단 자살 사건\n",
      "의 주범으로 악명높은\n",
      "짐 존스\n",
      "의 육성 연설이 샘플링되어 삽입되어 있다는 게 밝혀져 논란이 되었다. 이에 대해 슈가가 악플러들에 대한 반어적 비유를 사용하기 위해 짐 존스의 연설을 삽입한 거 아니냐는 의견과 존스타운과 전혀 관계없는 노래에 굳이 범죄자의 육성을 삽입한 이유가 궁금하다는 의견 등등 갑론을박이 벌어졌다.\n",
      "인민사원 집단 자살 사건\n",
      "이 국내에서는 별로 알려진 사건이 아니지만, 해당 사건이 일어난 국가 내에서는 꾸준히 교육시킬 정도로 심각했던 사건인 것은 사실이다.\n",
      "곡에 담긴 연설의 부분은 \"당신은 죽더라도 살 것이다. 살아서 믿는 자는 결코 죽지 않을 것이다.\"라는 내용이다. 다만 원래 이 문장은 요한복음 11장 25절에 있는 구절이다. 즉, 사이비 목사가 성경 내용을 악의적으로 이용한 것이다. 하지만 해당 연설 내용은 집단 자살 사건을 의미하기 때문에 문제가 된다. 해외에서도 짐 존스를 소재로 삼은 곡들이 꽤 있다. 포스트 말론의 '존스타운'과 릴 우지 버트의 'Leaders'는 가사에서 짐 존스가 언급되며,\n",
      "BROCKHAMPTON\n",
      "의 '1998 TRUMAN'는 짐 존스의 음성이 들어간다. 그러나 이 곡들은 모두 맥락의 부합성 면에서 슈가의 노래와 큰 차이점을 보인다.\n",
      "'존스타운'의 경우는 2분이 채 되지 않는 짧은 곡으로 앞 트랙의 흐름을 이어가는 역할이고, 'Leaders'의 경우에는 '짐 존스처럼 교단을 이끌어'라며 자신의 인기를 과시하기 위한 비유로 써 먹었다. '1998 TRUMAN'은 거대한 환상같은 현실 속 방탕한 삶을 사는 청년들의 현실을 폭로하는 내용으로, '너흰 자유가 아냐, 너흰 노예야!'라 외치는 짐 존스의 육성이 곡의 테마를 잡는다. 해당 아티스트들이 곡에서 짐 존스를 언급한 의도는 각자 다르고, 이에 대한 평가도 '범죄자 미화다', '예술의 영역이다', '수많은 피해자를 낳은 범죄자인데 육성 삽입 자체가 적절치 못했다' 등등 다 달랐다. 하여튼 슈가의 노래와 달리 짐 존스가 왜 등장했는지 그 의도와 맥락의 부합성이 분명하다는 공통점이 있다.\n",
      "해명\n",
      "논란이 일자 빅히트 엔터테인먼트(현\n",
      "빅히트 뮤직\n",
      ")는 \"도입부 연설 보컬 샘플은 해당 곡의 트랙을 작업한 프로듀서가 특별한 의도 없이 연설자를 알지 못한 상태에서 곡 전체의 분위기를 고려해 선정했다. 해당 연설 보컬 샘플을 선정한 이후 회사는 내부 프로세스에 따라 내용의 적정성을 확인하는 절차를 진행했다. 하지만 선정 및 검수 과정에서 내용상 부적절한 샘플임을 인지하지 못하고 곡에 포함하는 오류가 있었다.\"며 해명하고 공식 사과했다.\n",
      "#\n",
      "이후 연설 음성을 삭제한 음원을 재발매하였다. 이후 같은 곡에서 베트남 전범 범죄자의 연설을 사용했다는 루머가 추가로 나돌기도 하였으나 소속사인 빅히트 엔터테인먼트 측에서 \"사실무근\"이라며 이를 일축했다. 해당 소문은 단순 허위사실 루머인 것으로 확인되었다.\n",
      "#\n",
      "확인 결과, 논란이 된 짐 존스의 연설 샘플은 빅히트 프로듀서가 직접 짐 존스 연설 원본에서 샘플링한 것이 아니라 스플라이스라는 샘플 플랫폼에서 판매되고 있는 샘플이었다.\n",
      "#\n",
      "해당 곡의 트랙을 작업한 빅히트 프로듀서는 연설자가 누군지 모르고 실수로 해당 연설 보컬 샘플을 선정한 것으로 추측된다.\n",
      "또한 짐 존스 연설 샘플이 사용된 트랙 <어떻게 생각해?>의 크레딧을 확인해보면 슈가가 프로듀서 명단에 들어가있는 다른 곡들과 다르게 해당 곡은\n",
      "EL CAPITXN\n",
      ", GHSTLOOP만 프로듀서 명단에 들어가 있는 것을 확인할 수 있다. 즉, 실수로 해당 연설 보컬 샘플을 선정한 프로듀서는 슈가가 아니며 슈가는 이 노래에는 트랙이 아니라 작사, 녹음 등의 작업에만 참여했다.\n",
      "2.\n",
      "군대 관련 가사 논란\n",
      "[편집]\n",
      "국회\n",
      "에서까지 언급된 사건으로 짐 존스 연설 샘플링 논란이 되었던 곡 <어떻게 생각해?>에 \"Woo Woo, 군대는 때되면 알아서들 갈 테니까 우리 이름 팔아먹으면서 숟가락을 얹으려고 한 새끼들 싸그리 다 닥치길\"이라는 가사가 대중예술인 예술체육요원 대체복무 찬반 논란 때문에 화제가 되었고,\n",
      "국정감사\n",
      "에까지 이 가사가 오르내리게 되었다. 이후 슈가가 BTS에서 혼자만\n",
      "사회복무요원\n",
      "으로 복무하게 되어 한 번 더 논란이 되었다.\n",
      "#\n",
      "[[https://www.gynews.kr/news/articleView.html?idxno=20891|#]\n",
      "3.\n",
      "코로나바이러스감염증-19 관련 실언 논란\n",
      "[편집]\n",
      "--------------------------------------------------\n",
      "핵심 키워드: 인민사원 집단 자살 사건, 짐 존스, 연설, 도입부, 스캔들, 연결\n",
      "\n",
      "\n",
      "- 인민사원 집단 자살 사건\n",
      "- 짐 존스\n",
      "- 연설\n",
      "- 도입부\n",
      "- 스캔들\n",
      "- 연결\n",
      "\n",
      "- 인민사원 집단 자살 사건\n",
      "- 짐 존스\n",
      "- 연설\n",
      "- 도입부\n",
      "- 연결\n"
     ]
    }
   ],
   "source": [
    "### prac2\n",
    "prompt = \"\"\"\n",
    "다음 기사 내용을 분석하여, \n",
    "1. 기사에서 다루는 스캔들의 핵심 키워드를 중복 없이 3~5개 추출해 주세요. 스캔들에 포함된 사건과 관련된 요소가 있다면 반드시 포함해 주세요.\n",
    "2. 해당 스캔들의 유형을 분류할 때, 스캔들이 어떤 사건이나 논란(예: 음원 샘플링 논란, 가사/표현 논란, 사회적/정치적 이슈 등)에 근거하여 발생했는지를 명확하게 설명해 주세요. 특히, 인민사원 집단 자살 사건과 연결된 부분은 반드시 언급하여 분류에 반영해 주세요.\n",
    "\n",
    "출력 형식은 반드시 아래의 두 부분만 작성해 주세요:\n",
    "- 핵심 키워드: [키워드1, 키워드2, ...]\n",
    "- 스캔들 유형: [분류 결과]\n",
    "\n",
    "\n",
    "아래 기사를 참고하여 작업해 주세요.\n",
    "--------------------------------------------------\n",
    "2020년 5월 17일 발매된 슈가의 믹스테잎\n",
    "D-2\n",
    "의 수록곡 <어떻게 생각해?>의 도입부에\n",
    "인민사원 집단 자살 사건\n",
    "의 주범으로 악명높은\n",
    "짐 존스\n",
    "의 육성 연설이 샘플링되어 삽입되어 있다는 게 밝혀져 논란이 되었다. 이에 대해 슈가가 악플러들에 대한 반어적 비유를 사용하기 위해 짐 존스의 연설을 삽입한 거 아니냐는 의견과 존스타운과 전혀 관계없는 노래에 굳이 범죄자의 육성을 삽입한 이유가 궁금하다는 의견 등등 갑론을박이 벌어졌다.\n",
    "인민사원 집단 자살 사건\n",
    "이 국내에서는 별로 알려진 사건이 아니지만, 해당 사건이 일어난 국가 내에서는 꾸준히 교육시킬 정도로 심각했던 사건인 것은 사실이다.\n",
    "곡에 담긴 연설의 부분은 \"당신은 죽더라도 살 것이다. 살아서 믿는 자는 결코 죽지 않을 것이다.\"라는 내용이다. 다만 원래 이 문장은 요한복음 11장 25절에 있는 구절이다. 즉, 사이비 목사가 성경 내용을 악의적으로 이용한 것이다. 하지만 해당 연설 내용은 집단 자살 사건을 의미하기 때문에 문제가 된다. 해외에서도 짐 존스를 소재로 삼은 곡들이 꽤 있다. 포스트 말론의 '존스타운'과 릴 우지 버트의 'Leaders'는 가사에서 짐 존스가 언급되며,\n",
    "BROCKHAMPTON\n",
    "의 '1998 TRUMAN'는 짐 존스의 음성이 들어간다. 그러나 이 곡들은 모두 맥락의 부합성 면에서 슈가의 노래와 큰 차이점을 보인다.\n",
    "'존스타운'의 경우는 2분이 채 되지 않는 짧은 곡으로 앞 트랙의 흐름을 이어가는 역할이고, 'Leaders'의 경우에는 '짐 존스처럼 교단을 이끌어'라며 자신의 인기를 과시하기 위한 비유로 써 먹었다. '1998 TRUMAN'은 거대한 환상같은 현실 속 방탕한 삶을 사는 청년들의 현실을 폭로하는 내용으로, '너흰 자유가 아냐, 너흰 노예야!'라 외치는 짐 존스의 육성이 곡의 테마를 잡는다. 해당 아티스트들이 곡에서 짐 존스를 언급한 의도는 각자 다르고, 이에 대한 평가도 '범죄자 미화다', '예술의 영역이다', '수많은 피해자를 낳은 범죄자인데 육성 삽입 자체가 적절치 못했다' 등등 다 달랐다. 하여튼 슈가의 노래와 달리 짐 존스가 왜 등장했는지 그 의도와 맥락의 부합성이 분명하다는 공통점이 있다.\n",
    "해명\n",
    "논란이 일자 빅히트 엔터테인먼트(현\n",
    "빅히트 뮤직\n",
    ")는 \"도입부 연설 보컬 샘플은 해당 곡의 트랙을 작업한 프로듀서가 특별한 의도 없이 연설자를 알지 못한 상태에서 곡 전체의 분위기를 고려해 선정했다. 해당 연설 보컬 샘플을 선정한 이후 회사는 내부 프로세스에 따라 내용의 적정성을 확인하는 절차를 진행했다. 하지만 선정 및 검수 과정에서 내용상 부적절한 샘플임을 인지하지 못하고 곡에 포함하는 오류가 있었다.\"며 해명하고 공식 사과했다.\n",
    "#\n",
    "이후 연설 음성을 삭제한 음원을 재발매하였다. 이후 같은 곡에서 베트남 전범 범죄자의 연설을 사용했다는 루머가 추가로 나돌기도 하였으나 소속사인 빅히트 엔터테인먼트 측에서 \"사실무근\"이라며 이를 일축했다. 해당 소문은 단순 허위사실 루머인 것으로 확인되었다.\n",
    "#\n",
    "확인 결과, 논란이 된 짐 존스의 연설 샘플은 빅히트 프로듀서가 직접 짐 존스 연설 원본에서 샘플링한 것이 아니라 스플라이스라는 샘플 플랫폼에서 판매되고 있는 샘플이었다.\n",
    "#\n",
    "해당 곡의 트랙을 작업한 빅히트 프로듀서는 연설자가 누군지 모르고 실수로 해당 연설 보컬 샘플을 선정한 것으로 추측된다.\n",
    "또한 짐 존스 연설 샘플이 사용된 트랙 <어떻게 생각해?>의 크레딧을 확인해보면 슈가가 프로듀서 명단에 들어가있는 다른 곡들과 다르게 해당 곡은\n",
    "EL CAPITXN\n",
    ", GHSTLOOP만 프로듀서 명단에 들어가 있는 것을 확인할 수 있다. 즉, 실수로 해당 연설 보컬 샘플을 선정한 프로듀서는 슈가가 아니며 슈가는 이 노래에는 트랙이 아니라 작사, 녹음 등의 작업에만 참여했다.\n",
    "2.\n",
    "군대 관련 가사 논란\n",
    "[편집]\n",
    "국회\n",
    "에서까지 언급된 사건으로 짐 존스 연설 샘플링 논란이 되었던 곡 <어떻게 생각해?>에 \"Woo Woo, 군대는 때되면 알아서들 갈 테니까 우리 이름 팔아먹으면서 숟가락을 얹으려고 한 새끼들 싸그리 다 닥치길\"이라는 가사가 대중예술인 예술체육요원 대체복무 찬반 논란 때문에 화제가 되었고,\n",
    "국정감사\n",
    "에까지 이 가사가 오르내리게 되었다. 이후 슈가가 BTS에서 혼자만\n",
    "사회복무요원\n",
    "으로 복무하게 되어 한 번 더 논란이 되었다.\n",
    "#\n",
    "[[https://www.gynews.kr/news/articleView.html?idxno=20891|#]\n",
    "3.\n",
    "코로나바이러스감염증-19 관련 실언 논란\n",
    "[편집]\n",
    "--------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "output = llm(prompt, max_new_tokens=150, temperature=0.7, \n",
    "             do_sample=True  # 샘플링 활성화\n",
    "             )[0]['generated_text']\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjdrl\\anaconda3\\envs\\jsy\\Lib\\site-packages\\transformers\\modeling_utils.py:3405: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb9174528f04f608484926e796f5479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = \"./mistral-7b-local\"\n",
    "\n",
    "# 토크나이저 저장\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 크롤링한 파일 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740fbd70e5db448cbcf986de874cffdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 로그인\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['소속사', '그룹', '연예인 이름', '사건 날짜', '사건 내용 (날짜+내용 전체)'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/YG논란_크롤링.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 컬럼명 매핑\n",
    "COLUMN_NAME_MAP = {\n",
    "    \"소속사\": \"agency\",\n",
    "    \"그룹\": \"group\",\n",
    "    \"연예인 이름\": \"name\",\n",
    "    \"사건 날짜\": \"date\",\n",
    "    \"사건 내용 (날짜+내용 전체)\": \"content\"\n",
    "}\n",
    "\n",
    "def load_model(model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=\"auto\"\n",
    "    )\n",
    "    llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    return llm\n",
    "\n",
    "def extract_keywords_and_label(llm, text):\n",
    "    prompt = f\"\"\"\n",
    "다음은 연예인 논란과 관련된 기사입니다. 먼저 핵심 키워드 3~5개를 추출하고,\n",
    "이 키워드들을 기반으로 논란 유형을 하나로 분류해주세요.\n",
    "\n",
    "기사:\n",
    "\\\"{text}\\\"\n",
    "\n",
    "출력 형식:\n",
    "- 키워드1\n",
    "- 키워드2\n",
    "- ...\n",
    "- 논란 유형: [분류 결과만 간단하게]\n",
    "\"\"\"\n",
    "    output = llm(prompt, max_new_tokens=200, temperature=0.7, do_sample=True)[0]['generated_text']\n",
    "    \n",
    "    lines = output.strip().splitlines()\n",
    "    keywords = [line.strip('-• ').strip() for line in lines if line.strip().startswith(('-', '•')) and '논란 유형' not in line]\n",
    "    label_line = [line for line in lines if '논란 유형' in line]\n",
    "    label = label_line[0].split(\":\", 1)[-1].strip() if label_line else \"미확인\"\n",
    "\n",
    "    return keywords, label\n",
    "\n",
    "def load_and_classify(csv_path, article_col=\"사건 내용 (날짜+내용 전체)\", llm=None):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 컬럼명 공백 제거 (앞뒤 공백 제거)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # 결측치 제거: article_col 기준\n",
    "    df = df[df[article_col].notna()].copy()\n",
    "    \n",
    "    # 컬럼명 영어로 변경\n",
    "    df.rename(columns=COLUMN_NAME_MAP, inplace=True)\n",
    "    \n",
    "    keywords_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # 분류 작업: 기사 내용은 'content' 컬럼이 됨\n",
    "    for article in tqdm(df[\"content\"], desc=\"분류 중\"):\n",
    "        try:\n",
    "            keywords, label = extract_keywords_and_label(llm, article)\n",
    "        except Exception as e:\n",
    "            keywords, label = [], \"오류\"\n",
    "        keywords_list.append(keywords)\n",
    "        labels_list.append(label)\n",
    "    \n",
    "    df[\"keywords\"] = keywords_list\n",
    "    df[\"category\"] = labels_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "def classify_multiple_csvs(file_list, article_col, llm):\n",
    "    df_list = []\n",
    "    for file_path in file_list:\n",
    "        print(f\"\\n📄 처리 중: {file_path}\")\n",
    "        df = load_and_classify(file_path, article_col=article_col, llm=llm)\n",
    "        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014812240fb6415f90b6bb40cd224b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 처리할 CSV 파일 목록\n",
    "csv_paths = [\"./data/HYBE논란_크롤링.csv\", \"./data/YG논란_크롤링.csv\"]\n",
    "\n",
    "# LLM 모델 로드\n",
    "llm = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjdrl\\anaconda3\\envs\\jsy\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1569: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65017009624c78bb6fa46d50cfe62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 처리 중: ./data/HYBE논란_크롤링.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류 중:   0%|          | 0/76 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   1%|▏         | 1/76 [05:42<7:08:19, 342.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   3%|▎         | 2/76 [10:44<6:32:51, 318.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   4%|▍         | 3/76 [17:06<7:02:41, 347.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   5%|▌         | 4/76 [23:15<7:07:26, 356.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   7%|▋         | 5/76 [23:34<4:37:29, 234.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   8%|▊         | 6/76 [25:48<3:53:50, 200.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   9%|▉         | 7/76 [27:15<3:07:45, 163.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  11%|█         | 8/76 [30:19<3:12:36, 169.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  12%|█▏        | 9/76 [35:00<3:48:21, 204.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  13%|█▎        | 10/76 [36:41<3:10:00, 172.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  14%|█▍        | 11/76 [38:37<2:48:05, 155.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  16%|█▌        | 12/76 [43:35<3:32:06, 198.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  17%|█▋        | 13/76 [45:31<3:02:26, 173.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  18%|█▊        | 14/76 [46:53<2:30:42, 145.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  20%|█▉        | 15/76 [51:11<3:02:44, 179.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  21%|██        | 16/76 [56:01<3:32:54, 212.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  22%|██▏       | 17/76 [1:01:23<4:01:37, 245.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  24%|██▎       | 18/76 [1:02:51<3:11:38, 198.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  25%|██▌       | 19/76 [1:07:48<3:36:38, 228.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  26%|██▋       | 20/76 [1:12:30<3:47:58, 244.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  28%|██▊       | 21/76 [1:17:36<4:00:45, 262.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  29%|██▉       | 22/76 [1:20:32<3:33:07, 236.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  30%|███       | 23/76 [1:26:10<3:56:00, 267.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  32%|███▏      | 24/76 [1:29:11<3:29:07, 241.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  33%|███▎      | 25/76 [1:32:20<3:11:41, 225.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  34%|███▍      | 26/76 [1:37:04<3:22:25, 242.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  36%|███▌      | 27/76 [1:42:10<3:34:03, 262.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  37%|███▋      | 28/76 [1:46:55<3:35:07, 268.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  38%|███▊      | 29/76 [1:54:41<4:16:57, 328.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  39%|███▉      | 30/76 [1:59:54<4:07:56, 323.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  41%|████      | 31/76 [2:04:53<3:57:11, 316.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  42%|████▏     | 32/76 [2:07:45<3:20:07, 272.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  43%|████▎     | 33/76 [2:12:52<3:22:55, 283.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  45%|████▍     | 34/76 [2:16:37<3:06:01, 265.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  46%|████▌     | 35/76 [2:24:25<3:42:54, 326.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  47%|████▋     | 36/76 [2:29:37<3:34:39, 321.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  49%|████▊     | 37/76 [2:34:37<3:24:58, 315.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  50%|█████     | 38/76 [2:37:45<2:55:32, 277.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  51%|█████▏    | 39/76 [2:39:28<2:18:43, 224.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  53%|█████▎    | 40/76 [2:44:23<2:27:33, 245.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  54%|█████▍    | 41/76 [2:49:22<2:32:52, 262.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  55%|█████▌    | 42/76 [2:54:04<2:31:51, 267.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  57%|█████▋    | 43/76 [2:57:50<2:20:24, 255.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  58%|█████▊    | 44/76 [3:01:37<2:11:39, 246.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  59%|█████▉    | 45/76 [3:06:13<2:12:03, 255.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  61%|██████    | 46/76 [3:11:37<2:18:00, 276.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  62%|██████▏   | 47/76 [3:16:35<2:16:40, 282.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  63%|██████▎   | 48/76 [3:19:10<1:54:06, 244.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  64%|██████▍   | 49/76 [3:22:58<1:47:46, 239.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  66%|██████▌   | 50/76 [3:27:53<1:50:57, 256.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  67%|██████▋   | 51/76 [3:32:53<1:52:09, 269.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  68%|██████▊   | 52/76 [3:34:04<1:23:54, 209.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  70%|██████▉   | 53/76 [3:36:15<1:11:20, 186.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  71%|███████   | 54/76 [3:41:12<1:20:24, 219.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  72%|███████▏  | 55/76 [3:45:50<1:22:58, 237.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  74%|███████▎  | 56/76 [3:48:09<1:09:15, 207.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  75%|███████▌  | 57/76 [3:52:32<1:11:02, 224.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  76%|███████▋  | 58/76 [3:54:04<55:21, 184.55s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  78%|███████▊  | 59/76 [3:54:48<40:17, 142.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  79%|███████▉  | 60/76 [3:56:45<35:55, 134.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  80%|████████  | 61/76 [4:01:05<43:05, 172.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  82%|████████▏ | 62/76 [4:07:03<53:10, 227.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  83%|████████▎ | 63/76 [4:11:41<52:40, 243.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  84%|████████▍ | 64/76 [4:16:46<52:18, 261.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  86%|████████▌ | 65/76 [4:19:15<41:44, 227.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  87%|████████▋ | 66/76 [4:25:57<46:41, 280.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  88%|████████▊ | 67/76 [4:31:31<44:26, 296.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  89%|████████▉ | 68/76 [4:34:36<35:04, 263.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  91%|█████████ | 69/76 [4:39:21<31:26, 269.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  92%|█████████▏| 70/76 [4:42:18<24:10, 241.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  93%|█████████▎| 71/76 [4:47:09<21:22, 256.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  95%|█████████▍| 72/76 [4:53:06<19:07, 286.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  96%|█████████▌| 73/76 [4:57:45<14:13, 284.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  97%|█████████▋| 74/76 [5:02:51<09:41, 290.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  99%|█████████▊| 75/76 [5:04:38<03:55, 235.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중: 100%|██████████| 76/76 [5:11:21<00:00, 245.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 처리 중: ./data/YG논란_크롤링.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류 중:   0%|          | 0/44 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   2%|▏         | 1/44 [05:00<3:35:23, 300.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   5%|▍         | 2/44 [07:53<2:37:50, 225.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   7%|▋         | 3/44 [08:29<1:34:56, 138.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:   9%|▉         | 4/44 [14:03<2:23:52, 215.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  11%|█▏        | 5/44 [18:35<2:33:26, 236.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  14%|█▎        | 6/44 [20:37<2:05:05, 197.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  16%|█▌        | 7/44 [23:01<1:51:02, 180.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  18%|█▊        | 8/44 [26:14<1:50:22, 183.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  20%|██        | 9/44 [30:58<2:05:31, 215.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  23%|██▎       | 10/44 [32:26<1:39:43, 175.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  25%|██▌       | 11/44 [37:30<1:58:26, 215.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  27%|██▋       | 12/44 [42:35<2:09:16, 242.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  30%|██▉       | 13/44 [43:22<1:34:39, 183.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  32%|███▏      | 14/44 [48:17<1:48:32, 217.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  34%|███▍      | 15/44 [50:16<1:30:37, 187.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  36%|███▋      | 16/44 [52:12<1:17:27, 165.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  39%|███▊      | 17/44 [56:54<1:30:20, 200.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  41%|████      | 18/44 [1:02:18<1:43:09, 238.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  43%|████▎     | 19/44 [1:06:43<1:42:32, 246.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  45%|████▌     | 20/44 [1:11:31<1:43:26, 258.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  48%|████▊     | 21/44 [1:13:53<1:25:39, 223.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  50%|█████     | 22/44 [1:16:26<1:14:16, 202.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  52%|█████▏    | 23/44 [1:21:06<1:18:57, 225.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  55%|█████▍    | 24/44 [1:23:24<1:06:26, 199.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  57%|█████▋    | 25/44 [1:28:44<1:14:34, 235.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  59%|█████▉    | 26/44 [1:33:52<1:17:11, 257.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  61%|██████▏   | 27/44 [1:42:29<1:35:00, 335.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  64%|██████▎   | 28/44 [1:43:09<1:05:46, 246.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  66%|██████▌   | 29/44 [1:49:10<1:10:16, 281.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  68%|██████▊   | 30/44 [1:53:04<1:02:15, 266.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  70%|███████   | 31/44 [1:56:27<53:40, 247.74s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  73%|███████▎  | 32/44 [2:01:53<54:12, 271.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  75%|███████▌  | 33/44 [2:06:53<51:17, 279.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  77%|███████▋  | 34/44 [2:11:59<47:57, 287.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  80%|███████▉  | 35/44 [2:13:46<35:01, 233.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  82%|████████▏ | 36/44 [2:18:33<33:15, 249.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  84%|████████▍ | 37/44 [2:20:19<24:05, 206.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  86%|████████▋ | 38/44 [2:25:48<24:19, 243.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  89%|████████▊ | 39/44 [2:30:48<21:41, 260.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  91%|█████████ | 40/44 [2:35:54<18:15, 273.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  93%|█████████▎| 41/44 [2:40:37<13:50, 276.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  95%|█████████▌| 42/44 [2:42:28<07:34, 227.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중:  98%|█████████▊| 43/44 [2:47:17<04:05, 245.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "분류 중: 100%|██████████| 44/44 [2:52:46<00:00, 235.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 결과 저장됨: ./data/HYBE논란_크롤링_분류결과.csv\n",
      "분류 결과 저장됨: ./data/YG논란_크롤링_분류결과.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 CSV 파일에 대해 분류 작업 진행\n",
    "dfs = classify_multiple_csvs(file_list=csv_paths, article_col=\"사건 내용 (날짜+내용 전체)\", llm=llm)\n",
    "\n",
    "# 결과를 각각의 CSV 파일로 저장\n",
    "for csv_path, df in zip(csv_paths, dfs):\n",
    "    base_name = csv_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    output_path = f\"./data/{base_name}_분류결과.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"분류 결과 저장됨: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'소속사'\n",
      "'그룹'\n",
      "'연예인 이름'\n",
      "'사건 날짜'\n",
      "'사건 내용 (날짜+내용 전체)'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/HYBE논란_크롤링.csv\")\n",
    "for col in df.columns:\n",
    "    print(repr(col))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsy",
   "language": "python",
   "name": "jsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
